{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.ensemble import RandomForestRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/521604975992772292', creation_time=1742928607503, experiment_id='521604975992772292', last_update_time=1742928607503, lifecycle_stage='active', name='Diabetes', tags={}>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set our tracking srver uri for logging\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:8080/\")\n",
    "\n",
    "# Create a new MLFlow Experiment\n",
    "mlflow.set_experiment(\"Diabetes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/25 15:51:19 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "2025/03/25 15:51:20 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'd14bc45806c0491fb83dcc823802d99c', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run bouncy-dolphin-79 at: http://127.0.0.1:8080/#/experiments/521604975992772292/runs/d14bc45806c0491fb83dcc823802d99c\n",
      "üß™ View experiment at: http://127.0.0.1:8080/#/experiments/521604975992772292\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mlflow.autolog()\n",
    "\n",
    "db = load_diabetes()\n",
    "X_train, X_test, y_train, y_test = train_test_split(db.data, db.target)\n",
    "\n",
    "# Create and train models.\n",
    "rf = RandomForestRegressor(n_estimators=100, max_depth=6, max_features=3)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Use the model to make predictions on the test dataset.\n",
    "predictions = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from random import random, randint\n",
    "from mlflow import log_metric, log_param, log_params, log_artifacts\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Log a parameter (key-value pair)\n",
    "    log_param(\"config_value\", randint(0, 100))\n",
    "\n",
    "    # Log a dictionary of parameters\n",
    "    log_params({\"param1\": randint(0, 100), \"param2\": randint(0, 100)})\n",
    "\n",
    "    # Log a metric; metrics can be updated throughout the run\n",
    "    log_metric(\"accuracy\", random() / 2.0)\n",
    "    log_metric(\"accuracy\", random() + 0.1)\n",
    "    log_metric(\"accuracy\", random() + 0.2)\n",
    "\n",
    "    # Log an artifact (output file)\n",
    "    if not os.path.exists(\"outputs\"):\n",
    "        os.makedirs(\"outputs\")\n",
    "    with open(\"outputs/test.txt\", \"w\") as f:\n",
    "        f.write(\"hello world!\")\n",
    "    log_artifacts(\"outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
